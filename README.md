# Jitendra Kumar Dhiman ‚Äî AL/ML Researcher  

üåê [Website](https://jitendradhiman.github.io/) ‚Ä¢ [LinkedIn](https://www.linkedin.com/in/YOUR-LINK) ‚Ä¢ ![GitHub followers](https://img.shields.io/github/followers/Jitendradhiman?label=Follow&style=social) ‚Ä¢ ![Profile views](https://komarev.com/ghpvc/?username=Jitendradhiman&color=blue)  

üöÄ Advancing speech & audio technologies ‚Äî from signal processing research to real-world ML systems  
üìç Bangalore, India

---

## üë®‚Äçüíª About Me  

I‚Äôm **Jitendra Kumar Dhiman**, a researcher specializing in **speech and audio machine learning**.  
Over the past decade, I‚Äôve worked across **research and industry**, advancing **speech/audio technologies** including **text-to-speech (TTS)**, **automatic speech recognition (ASR)**, and **audio codecs**.  

Currently, I‚Äôm a **Senior Engineer Lead** at **Qualcomm R&D India**, focusing on **scalable speech/audio codecs**.  
Previously, I led the development of **multilingual ASR systems** at **Samsung R&D India**.  

---

## üíº Professional Experience  

- **Senior Engineer Lead** ‚Äî Qualcomm R&D India *(Nov 2024 ‚Äì Present)*  
  - Driving research and development of **scalable speech/audio codecs** for next-generation communication systems.  
  - Designed and deployed a **continuous bandwidth detector** enabling **robust WB/NB mode switching** in satellite communication.  
  - Filed a **patent** for the novel bandwidth detection technique.  
  **Technologies used:** C, Python, Signal Processing  

- **Chief Engineer** ‚Äî Samsung R&D India *(Dec 2021 ‚Äì Nov 2024)*  
  - Conducted **research and prototyping** of **multilingual ASR systems** leveraging **RNN-T architectures and conformers**.  
  - Applied **self-supervised learning (SSL)** methods (e.g., **wav2vec2**) to enhance performance for multilingual ASR.  
  - Developed a **Language Identification (LID) system** using **LoRA fine-tuning and attention mechanisms**, achieving **~99% accuracy** across diverse languages.  
  - Mentored and guided junior engineers in **speech ML research, prototyping, and experimentation**, fostering a strong applied research culture.  
  **Technologies used:** PyTorch, TensorFlow, C, Docker, Kubernetes  

- **Project Associate** ‚Äî IISc Bangalore & IIT Hyderabad *(2013‚Äì2014)*  
  - Developed and integrated a **real-time time-scale modification algorithm** for speech, successfully deployed in **Hindi TTS systems** in collaboration with **C-DAC Mumbai**.  
  - Contributed to projects on **prosody modification, phonetic engines, and text-to-speech (TTS)**, including data preparation and prototyping.  
  **Technologies used:** MATLAB, C, Speech Processing Toolkits  

## üéì Education  

- **PhD in Speech Signal Processing** ‚Äî IISc Bangalore *(2014‚Äì2021)*  
- **MTech in Signal Processing** ‚Äî IIT Hyderabad *(2013)*  
- **BTech in Electronics & Telecommunication** ‚Äî IETE New Delhi *(2010)*  

---

## üî¨ Research Interests  

- Speech & Audio Signal Processing  
- Machine Learning for Time series data
- Speech Synthesis & Enhancement
- Generative & Sequence-to-Sequence Models
- Large Language Models

---

## üõ† Skills Matrix  

| Category | Tools & Technologies |
|----------|-----------------------|
| **Programming Languages** | Python, C, C++, MATLAB, Shell |
| **AI / ML** | PyTorch, TensorFlow, Scikit-learn |
| **Speech & Audio Processing** | ASR, TTS, Speech Enhancement, Audio Codecs, DSP |
| **Generative Models** | WaveNet, Transformer-based ASR/TTS, Self-Supervised Speech Models (wav2vec2, HuBERT) |
| **Data Handling** | NumPy, Pandas, SciPy, HDF5 |
| **Research & Writing** | LaTeX, Technical Writing, Conference Presentations |

<!-- | **Edge / Deployment** | Docker | -->
<!-- | **Optimization / Performance** | Quantization, Pruning, Knowledge Distillation, Low-Latency Inference | -->

---

## üìÑ Publications  

- *Musical Noise Suppression Using a Low-Rank and Sparse Matrix Decomposition Approach*, **Speech Communication**, 2020  
- *On the Suitability of the Riesz Spectro-Temporal Envelope for WaveNet Based Speech Synthesis*, **INTERSPEECH 2019**  
- *A Spectro-Temporal Technique for Estimating Aperiodicity and Voiced/Unvoiced Decision Boundaries*, **ICASSP 2019**  
‚û°Ô∏è [Full list on my website](https://jitendradhiman.github.io/)  

---

üìß Reach me at **jkdiith@gmail.com**  

---